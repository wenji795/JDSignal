# é‡ç½®æ•°æ®åº“å¹¶æµ‹è¯• AI å¢å¼ºæå–åŠŸèƒ½

## âœ… æ•°æ®åº“å·²é‡ç½®

æ•°æ®åº“æ–‡ä»¶å·²åˆ é™¤å¹¶é‡æ–°åˆ›å»ºã€‚ç°åœ¨å¯ä»¥å¼€å§‹é‡æ–°æŠ“å–æ•°æ®æ¥æµ‹è¯• AI å¢å¼ºæå–åŠŸèƒ½ã€‚

## ğŸ“‹ æ­¥éª¤

### 1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰

åˆ›å»º `backend/.env` æ–‡ä»¶å¹¶æ·»åŠ ä½ çš„ AI Builder Tokenï¼š

```bash
cd backend
echo "AI_BUILDER_TOKEN=your_token_here" > .env
```

**è·å– Tokenï¼š**
- è®¿é—® https://space.ai-builders.com/explorer
- ç™»å½•åæŸ¥çœ‹å³ä¸Šè§’çš„ "Authorize" æŒ‰é’®
- æˆ–è€…ä½¿ç”¨ MCP å·¥å…· `get_auth_token` è·å–

### 2. å¯åŠ¨åç«¯æœåŠ¡

åœ¨ç»ˆç«¯1ä¸­å¯åŠ¨åç«¯æœåŠ¡ï¼š

```bash
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

ç¡®ä¿æœåŠ¡æ­£å¸¸è¿è¡Œï¼Œä½ åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š
```
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 3. è¿è¡ŒæŠ“å–è„šæœ¬

åœ¨ç»ˆç«¯2ä¸­è¿è¡ŒæŠ“å–è„šæœ¬ï¼š

```bash
cd backend
python scripts/reset_and_scrape.py --max-per-keyword 5 --headless
```

**å‚æ•°è¯´æ˜ï¼š**
- `--max-per-keyword 5`: æ¯ä¸ªå…³é”®è¯æœ€å¤šæŠ“å–5ä¸ªèŒä½ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
- `--headless`: ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼‰
- `--browser firefox`: æŒ‡å®šæµè§ˆå™¨å¼•æ“ï¼ˆé»˜è®¤firefoxï¼‰

**å®Œæ•´æŠ“å–ï¼ˆæ›´å¤šæ•°æ®ï¼‰ï¼š**
```bash
python scripts/reset_and_scrape.py --max-per-keyword 10 --headless
```

### 4. éªŒè¯ AI æå–ç»“æœ

æŠ“å–å®Œæˆåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯ï¼š

#### æ–¹æ³•1ï¼šä½¿ç”¨ API æ–‡æ¡£

è®¿é—® http://localhost:8000/docs

1. è°ƒç”¨ `GET /jobs` æŸ¥çœ‹æ‰€æœ‰èŒä½
2. é€‰æ‹©ä¸€ä¸ªèŒä½ID
3. è°ƒç”¨ `GET /jobs/{job_id}` æŸ¥çœ‹èŒä½è¯¦æƒ…
4. æ£€æŸ¥ `extraction` å­—æ®µï¼š
   - `extraction_method`: åº”è¯¥æ˜¯ `"ai-enhanced"` æˆ– `"rule-based"`
   - `summary`: å¦‚æœä½¿ç”¨AIæå–ï¼Œåº”è¯¥æœ‰èŒä½æ‘˜è¦
   - `keywords_json`: åŒ…å«æå–çš„å…³é”®è¯

#### æ–¹æ³•2ï¼šä½¿ç”¨ curl

```bash
# è·å–æ‰€æœ‰èŒä½
curl http://localhost:8000/jobs | jq '.[0].extraction.extraction_method'

# è·å–ç‰¹å®šèŒä½çš„è¯¦ç»†ä¿¡æ¯
curl http://localhost:8000/jobs/{job_id} | jq '.extraction'
```

#### æ–¹æ³•3ï¼šæ£€æŸ¥æ•°æ®åº“

```bash
cd backend
python -c "
from sqlmodel import Session, select, create_engine
from app.models import Extraction
engine = create_engine('sqlite:///./jobs.db')
with Session(engine) as session:
    extractions = session.exec(select(Extraction)).all()
    ai_count = sum(1 for e in extractions if e.extraction_method == 'ai-enhanced')
    rule_count = sum(1 for e in extractions if e.extraction_method == 'rule-based')
    print(f'AIå¢å¼ºæå–: {ai_count}')
    print(f'è§„åˆ™æå–: {rule_count}')
    print(f'æ€»è®¡: {len(extractions)}')
"
```

## ğŸ” é¢„æœŸç»“æœ

### AI å¢å¼ºæå–æˆåŠŸæ—¶

```json
{
  "extraction": {
    "extraction_method": "ai-enhanced",
    "summary": "è¿™æ˜¯ä¸€ä¸ªä¸­çº§åç«¯å¼€å‘èŒä½ï¼Œéœ€è¦Pythonå’ŒFastAPIç»éªŒ...",
    "keywords_json": {
      "keywords": ["Python", "FastAPI", "PostgreSQL", ...]
    },
    "must_have_json": {
      "keywords": ["Python", "FastAPI", ...]
    },
    "nice_to_have_json": {
      "keywords": ["Docker", "Kubernetes", ...]
    }
  },
  "role_family": "backend",
  "seniority": "mid"
}
```

### å›é€€åˆ°è§„åˆ™æå–æ—¶

```json
{
  "extraction": {
    "extraction_method": "rule-based",
    "summary": null,
    "keywords_json": {
      "keywords": [...]
    }
  }
}
```

## âš ï¸ æ•…éšœæ’é™¤

### AI æå–å¤±è´¥ï¼ˆæ˜¾ç¤º rule-basedï¼‰

1. **æ£€æŸ¥ç¯å¢ƒå˜é‡**ï¼š
   ```bash
   cd backend
   cat .env | grep AI_BUILDER_TOKEN
   ```

2. **æ£€æŸ¥åç«¯æ—¥å¿—**ï¼šæŸ¥çœ‹æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯

3. **æ‰‹åŠ¨æµ‹è¯• API**ï¼š
   ```bash
   curl -X POST http://localhost:8000/manual-job \
     -H "Content-Type: application/json" \
     -d '{
       "title": "Test Job",
       "company": "Test Company",
       "jd_text": "We need a Python developer with FastAPI experience."
     }'
   ```

### æŠ“å–å¤±è´¥

1. **ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ**
2. **æ£€æŸ¥ç½‘ç»œè¿æ¥**
3. **æ£€æŸ¥ Playwright æµè§ˆå™¨æ˜¯å¦å·²å®‰è£…**ï¼š
   ```bash
   playwright install firefox
   ```

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

æŠ“å–å®Œæˆåï¼Œå¯ä»¥è¿è¡Œä»¥ä¸‹è„šæœ¬æŸ¥çœ‹ç»Ÿè®¡ï¼š

```bash
cd backend
python -c "
from sqlmodel import Session, select, create_engine
from app.models import Job, Extraction
engine = create_engine('sqlite:///./jobs.db')
with Session(engine) as session:
    jobs = session.exec(select(Job)).all()
    extractions = session.exec(select(Extraction)).all()
    
    print(f'èŒä½æ€»æ•°: {len(jobs)}')
    print(f'æå–ç»“æœæ€»æ•°: {len(extractions)}')
    
    ai_extractions = [e for e in extractions if e.extraction_method == 'ai-enhanced']
    rule_extractions = [e for e in extractions if e.extraction_method == 'rule-based']
    
    print(f'AIå¢å¼ºæå–: {len(ai_extractions)} ({len(ai_extractions)/len(extractions)*100:.1f}%)')
    print(f'è§„åˆ™æå–: {len(rule_extractions)} ({len(rule_extractions)/len(extractions)*100:.1f}%)')
    
    summaries = [e for e in extractions if e.summary]
    print(f'æœ‰æ‘˜è¦çš„èŒä½: {len(summaries)}')
"
```

## ğŸ‰ å®Œæˆï¼

å¦‚æœçœ‹åˆ° `extraction_method: "ai-enhanced"` å’Œ `summary` å­—æ®µæœ‰å†…å®¹ï¼Œè¯´æ˜ AI å¢å¼ºæå–åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼
